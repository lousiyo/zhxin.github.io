[{"content":"变量 脚本开头使用#!/bin/bash指定要使用的shell,shell会通过PATH环境变量来查找脚本中使用的命令，可以使用echo $PATH来看下脚本会在哪些目录下查找命令，如果脚本中执行的命令没有在PATH环境变量中，也可以通过绝对或相对路径来引用.\n在脚本中可以使用shell维护的环境变量也可以定义和使用自己的用户变量.\n赋值等号两边不能存在空格\n环境变量：\n可以使用set命令查看当前环境变量列表,例如$HOME、$HOSTNAME、$USER等;\n用户变量：\n由字母数字下划线组成，长度不超过二十，区分大小写，变量、等号、值之间不能有空格，在shell脚本结束时会被删除掉，使用美元符号引用，例如name=\u0026quot;test\u0026quot;。\n使用用户变量保存命令执行结果：testing=$(date)\n特殊参数变量\n参数 描述 $ 0 $1 $2 入参 $# 参数个数 $* 入参列表，将所有参数当作单个参数 $@ 入参列表，单独处理每个参 重定向输入输出 输出重定向: \u0026gt; 追加：\u0026gt;\u0026gt;\n输入重定向: \u0026lt; 在脚本中使用\u0026lt; \u0026gt; 需要进行转义\\\u0026lt; \\\u0026gt;\n内联输入重定向：\ncommand \u0026lt;\u0026lt; marker content marker # 例如： wc -l \u0026lt;\u0026lt;EOF echo \u0026#34;aaa\u0026#34; echo \u0026#34;BBB\u0026#34; EOF 内联重定向到文件\ncat \u0026gt;\u0026gt; demo.txt \u0026lt;\u0026lt;EOF some content EOF 文件描述符 缩写 描述 0 STDIN 标准输入 1 STDOUT 标准输出 2 STDERR 标准错误 \u0026amp;\u0026gt; 符号会将所有输出重定向到一个文件内\nexec 1\u0026gt;testout 在脚本中将STDOUT永久重定向到testout\nexec 3\u0026gt;./testfile 创建写描述符3\nexec 3\u0026gt;\u0026amp;- 关闭文件描述符3\ncat /dev/null \u0026gt; file.log 可快速清空日志\n脚本中执行数学运算 使用美元符和方括号，只支持整型计算 var1=$[1 + 5]\nvar2=$[$var1 * 2]\nvar3=$[2 / 3]\n2. 通过bc进行浮点型计算:\nvar1=$(echo \u0026#34;scale=4; 3.44 / 5\u0026#34; | bc) var1=10.46 var2=43.67 var3=33.2 var4=71 var5=$(bc\u0026lt;\u0026lt;EOF scale = 4 a1=($var1 * $var2) b1=($var3 * $var4) a1+b1 EOF ) echo \u0026#34;$var5\u0026#34; ## 退出脚本 默认情况shell会以脚本最后一个命令的退出状态码退出(0-255)\\ 可以使用exit命令指定脚本的退出码，并通过`echo $?`查看程序是否执行成功 ## 结构化命令 ### if语句 根据命令执行是否成功走不同分支 ```bash if command1; then comands elif comand2; then comands else comands fi 或者使用条件测试的方式\nif [ condition ];then comands fi 条件测试 数值比较\n比较 描述 n1 -eq n2 检查相等 n1 -ge n2 检查n1是否大于或等于n2 n1 -gt n2 检查n1是否大于n2 n1 -le n2 检查n1是否小于或等于n2 n1 -lt n2 检查n1是否小于n2 n1 -ne n2 检查n1是否不等于n2 字符串比较\n比较 描述 str1 = str2 是否相同 str1 != str2 是否不同 str1 \u0026lt; str2 str1是否比str2大 str1 \u0026gt; str2 str1是否比str2小 -n str1 检查str1的长度是否非0 -z str1 检查str1的长度是否为0 文件比较\n比较 描述 -d file file是否存在并是目录 -e file file是否存在 -f file file是否存在并是文件 -r file 是否存在并可读 -s file 是否存在并非空 -w file 是否存在并可写 -x file 是否存在并可执行 -O file 是否存在并属于当前用户所有 -G file 是否存在并默认组与当前用户相同 file1 -nt file2 file1是否比file2新 file1 -ot file2 file1是否比file2旧 复合条件测试\n[ conditon1 ] \u0026amp;\u0026amp; [ condition2 ]\n[ conditon1 ] || [ condition2 ]\n使用双括号进行数学运算判断 (( expression ))，支持的运算符号除普通运算符外还包括如下，大于小于符号不用转义 . val++ 、val--、 ++val、 --val ：自增自减\n! :求反 ~:位求反 **:幂运算 \u0026lt;\u0026lt;：左位移 \u0026gt;\u0026gt;:右位移 \u0026amp;:位布尔和|：位布尔或 \u0026amp;\u0026amp;：逻辑和 ||:逻辑或\n可以在if语句中使用双括号命令，也可以在脚本中的普通命令里使用来赋值\n使用双方括号进行字符串比较 [[ express ]]\nbash shell支持模式匹配: if [[ $USER == r* ]]\ncase语句 case variable in pattern1 | pattern2) commands1;; pattern3) comands2;; *) default commands;; esac for语句 for var in list do commands:$var done 有时候使用for line in $(cat $file)读取文本文件，默认会以空格分隔而不是换行符,需要修改IFS.\nIFS值：内部字段分隔符\nIFS.OLD=$IFS IFS=$’\\n’ #\u0026lt;在代码中使用新的IFS值\u0026gt; IFS=$IFS.OLD C语言风格for语句\nfor (( i=1; i \u0026lt;=10; i++ )) do ... done while语句 while [ condition ] do other commands done break: 跳出内部循环\ncontinue: 跳过本次循环\nbreak n: 可跳出外部循环\ncontinue n : 继续循环层级n的循环\n处理用户输入 利用getopts处理用户输入参数\nwhile getopts :ab:c opt do case \u0026#34;$opt\u0026#34; in a) echo \u0026#34;found -a option\u0026#34; ;; b) echo \u0026#34;found -b option ,with value $OPTARG\u0026#34; ;; c) echo \u0026#34;found -c option\u0026#34; ;; *) echo \u0026#34;Unknown option: $opt\u0026#34; ;; esac done shift $[ $OPTIND - 1 ] count=1 for param in \u0026#34;$@\u0026#34; do echo \u0026#34;Parameter $count: $param\u0026#34; count=$[ $count + 1] done 获取用户输入\nif read -t 10 -p \u0026#34;Please enter your name: \u0026#34; name then echo \u0026#34;ok: $name\u0026#34; else echo \u0026#34;too slow\u0026#34; exit 1 fi 使用临时文件 tempfile=$(mktemp tmp.XXXXXX) exec 3\u0026gt;$tempfile echo “test” \u0026gt;\u0026amp;3 exec 3\u0026gt;\u0026amp;- rm -f $tempfile 2\u0026gt;/dev/null mktemp -t 生成在/tmp/目录下，返回全路径 控制脚本 记录消息 date | tee -a testfile trap捕获处理信号 trap commands signals\ntrap “echo ‘ sorry i have trapped Ctrl-C’” SIGINT\ntrap -- SIGINT 删除捕获 3. 后台作业相关 command \u0026amp;：后台运行\nnohup comand: 后台运行\njobs: 列举作业\nbg: 后台重启作业\nfg: 将后台作业调到前台继续执行,可指定job号\nnice renice: 调整作业优先级\nat: 定时执行作业\natq: 定时作业队列\natrm: 删除作业\ncrontab定时任务时间表：\nmin hour dayofmonth month dayofweek command\nanacron:开机执行错过作业\nshell函数 函数名必须唯一，否则会有问题 function name{ commands } [[或者]] name() { commands } return 可以返回函数值：必须函数一结束就取$?;退出的状态码必须是0-255\n超出255值可以使用 result=$(func1) 方式\n每个函数可以单独使用自己的$# $1 $2 环境参数\n变量作用域：\n全局变量：不管在函数内外定义，脚本所有位置都可访问\n局部变量：必须用local关键字显式声明\nlocal temp=$[ $value + 5]\n数组相关：\n函数参数是数组情况处理：\nfunction testit { local newarray newarray=(\u0026#39;echo \u0026#34;$@\u0026#34;\u0026#39;) echo “The new array value is: ${newarray[*]}” } myarray=(1 2 3 4 5) testit ${myarray[*]} 多进程执行函数 function multi {} multi argu1\u0026amp; multi argu2\u0026amp; multi argu3\u0026amp; wait trap捕获信号 Trapping ctrl-c in Bash You can use the trap builtin to handle a user pressing ctrl-c during the execution of a Bash script. e.g. if you need to perform some cleanup functions.\n#!/bin/bash [[trap]] ctrl-c and call ctrl_c() trap ctrl_c INT function ctrl_c() { echo \u0026#34;** Trapped CTRL-C\u0026#34; } for i in `seq 1 5`; do sleep 1 echo -n \u0026#34;.\u0026#34; done debug 在调用脚本的时候开启deubg sh -x shell.sh 在脚本文件首行开启deubg #!/bin/bash -x 使用set开启deubg set -x -v 显示脚本所有行，详细模式，在脚本嵌套调用时比较有用 sh -v shell.sh -n 检查脚本的语法，不执行脚本的命令 sh -n shell.sh 远程执行命令 ssh -n \u0026lsquo;command\u0026rsquo; 可避免在while循环中吞stdin数据\n工具推荐 shtool ShellCheck\n","permalink":"https://zhxin.xyz/post/2021/06/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/","summary":"变量 脚本开头使用#!/bin/bash指定要使用的shell,shell会通过PATH环境变量来查找脚本中使用的命令，可以使用echo $PATH来看下脚本会在哪些目录下查找命令，如果脚本中执行的命令没有在PATH环境变量中，也可以通过绝对或相对路径来引用. 在脚本中可以使用shell维护的环境变量也可以定义和使用自己的用户变量. 赋值等号两边不能存在空格 环境变量： 可以使用set命令查看当前环境变量列表","title":"Shell编程基础"},{"content":"最近看了PG状态转换的过程,代码细节没有仔细研究，先粗略过了一遍代码，特此记录.\nPG PG是存储池的基本单元，是一些对象的集合，多副本和纠删的数据备份策略依托PG实现. PG有多种状态，状态之间的变化通过状态机实现.\n有两个场景会触发peering流程：\n在pg创建时 在OSD启动、停止导致OSDMap变化进而导致pg的acting set发生变化时 状态机 状态机在创建PG进行初始化.\nclass RecoveryMachine : public boost::statechart::state_machine\u0026lt; RecoveryMachine, Initial \u0026gt; { RecoveryState *state; public: PG *pg; utime_t event_time; uint64_t event_count; ... boost::statechat包含对象：\nstate_machine: 状态机 state: 状态 event：事件 可通过process_event函数进行事件投递 transition / custom_reaction: 转移/反应 custom_reaction通过对于react函数进行处理 PG状态机的对象、状态及时间处理主要在PG.h、PG.cc文件中. struct Initial : boost::statechart::state\u0026lt; Initial, RecoveryMachine \u0026gt;, NamedState { explicit Initial(my_context ctx); void exit(); typedef boost::mpl::list \u0026lt; boost::statechart::transition\u0026lt; Initialize, Reset \u0026gt;, boost::statechart::custom_reaction\u0026lt; Load \u0026gt;, boost::statechart::custom_reaction\u0026lt; NullEvt \u0026gt;, boost::statechart::transition\u0026lt; boost::statechart::event_base, Crashed \u0026gt; \u0026gt; reactions; boost::statechart::result react(const Load\u0026amp;); boost::statechart::result react(const MNotifyRec\u0026amp;); boost::statechart::result react(const MInfoRec\u0026amp;); boost::statechart::result react(const MLogRec\u0026amp;); boost::statechart::result react(const boost::statechart::event_base\u0026amp;) { return discard_event(); } }; PG状态机主要包含的状态如下图:\nPrimary Peering Primary Peering过程中状态机流程图如下图所示，并没有展示从OSD和Recovery、Backfill过程.\n主OSD接受到pg_create消息开始创建PG\nvoid OSD::handle_pg_create(OpRequestRef op) { MOSDPGCreate *m = (MOSDPGCreate*)op-\u0026gt;get_req(); assert(m-\u0026gt;get_type() == MSG_OSD_PG_CREATE); dout(10) \u0026lt;\u0026lt; \u0026#34;handle_pg_create \u0026#34; \u0026lt;\u0026lt; *m \u0026lt;\u0026lt; dendl; ... 依次调用handle_pg_create-\u0026gt; handle_pg_peering_evt -\u0026gt; _create_lock_pg -\u0026gt; _open_lock_pg -\u0026gt; _make_pg,创建PG.\nPG* OSD::_make_pg( OSDMapRef createmap, spg_t pgid) { dout(10) \u0026lt;\u0026lt; \u0026#34;_open_lock_pg \u0026#34; \u0026lt;\u0026lt; pgid \u0026lt;\u0026lt; dendl; PGPool pool = _get_pool(pgid.pool(), createmap); // create PG *pg; if (createmap-\u0026gt;get_pg_type(pgid.pgid) == pg_pool_t::TYPE_REPLICATED || createmap-\u0026gt;get_pg_type(pgid.pgid) == pg_pool_t::TYPE_ERASURE) pg = new ReplicatedPG(\u0026amp;service, createmap, pool, pgid); else assert(0); return pg; } 创建PG完成之后,在handle_pg_create -\u0026gt; handle_pg_peering_evt -\u0026gt; handle_create 函数中,开始进行事件投递和事件的处理.\nvoid PG::handle_create(RecoveryCtx *rctx) { dout(10) \u0026lt;\u0026lt; \u0026#34;handle_create\u0026#34; \u0026lt;\u0026lt; dendl; rctx-\u0026gt;created_pgs.insert(this); Initialize evt; recovery_state.handle_event(evt, rctx); ActMap evt2; recovery_state.handle_event(evt2, rctx); } 在创建之初，状态机处于Initial状态，在此状态下创建一个Initialize事件，状态机的handle_event函数会调用process_event函数将事件投递出去.\n可以看到在Initial状态下接受到Initialize事件之后，状态机直接转换为Reset状态.先调用Reset构造函数,然后带着状态重新回到handle_create函数处，继续创建ActMap事件然后投递出去.\nReset状态下接收到ActMap事件后在对应定义的react函数中进行处理.\nboost::statechart::result PG::RecoveryState::Reset::react(const ActMap\u0026amp;) { PG *pg = context\u0026lt; RecoveryMachine \u0026gt;().pg; if (pg-\u0026gt;should_send_notify() \u0026amp;\u0026amp; pg-\u0026gt;get_primary().osd \u0026gt;= 0) { context\u0026lt; RecoveryMachine \u0026gt;().send_notify( pg-\u0026gt;get_primary(), pg_notify_t( pg-\u0026gt;get_primary().shard, pg-\u0026gt;pg_whoami.shard, pg-\u0026gt;get_osdmap()-\u0026gt;get_epoch(), pg-\u0026gt;get_osdmap()-\u0026gt;get_epoch(), pg-\u0026gt;info), pg-\u0026gt;past_intervals); } pg-\u0026gt;update_heartbeat_peers(); pg-\u0026gt;take_waiters(); return transit\u0026lt; Started \u0026gt;(); } 在react函数中，状态直接转换到Started状态, Started状态定义了子状态，则直接跳转到Start子状态.\nstruct Started : boost::statechart::state\u0026lt; Started, RecoveryMachine, Start \u0026gt;, NamedState { explicit Started(my_context ctx); void exit(); typedef boost::mpl::list \u0026lt; boost::statechart::custom_reaction\u0026lt; QueryState \u0026gt;, boost::statechart::custom_reaction\u0026lt; AdvMap \u0026gt;, boost::statechart::custom_reaction\u0026lt; NullEvt \u0026gt;, boost::statechart::custom_reaction\u0026lt; FlushedEvt \u0026gt;, boost::statechart::custom_reaction\u0026lt; IntervalFlush \u0026gt;, boost::statechart::transition\u0026lt; boost::statechart::event_base, Crashed \u0026gt; \u0026gt; reactions; boost::statechart::result react(const QueryState\u0026amp; q); boost::statechart::result react(const AdvMap\u0026amp;); boost::statechart::result react(const FlushedEvt\u0026amp;); boost::statechart::result react(const IntervalFlush\u0026amp;); boost::statechart::result react(const boost::statechart::event_base\u0026amp;) { return discard_event(); } }; 查看Start状态的构造函数\n/*-------Start---------*/ PG::RecoveryState::Start::Start(my_context ctx) : my_base(ctx), NamedState(context\u0026lt; RecoveryMachine \u0026gt;().pg-\u0026gt;cct, \u0026#34;Start\u0026#34;) { context\u0026lt; RecoveryMachine \u0026gt;().log_enter(state_name); PG *pg = context\u0026lt; RecoveryMachine \u0026gt;().pg; if (pg-\u0026gt;is_primary()) { dout(1) \u0026lt;\u0026lt; \u0026#34;transitioning to Primary\u0026#34; \u0026lt;\u0026lt; dendl; post_event(MakePrimary()); } else { //is_stray dout(1) \u0026lt;\u0026lt; \u0026#34;transitioning to Stray\u0026#34; \u0026lt;\u0026lt; dendl; post_event(MakeStray()); } } 首先获取当前处理的PG，判断当前osd是不是该pg的主osd，如果是的话则投递MakePrimary事件，否则投递MakeStray事件，如果进入Stray状态则对应PG实例需要由当前Primary按照Peering的进度和结果进一步确认其身份.\n按照主OSD的路径继续走, 在Start状态下接受到MakePrimary事件后，状态机会依次进入到Started/Primary/Peering/Getinfo，进入peering阶段。\nGetInfo过程获取该PG在其他OSD上的pg_info_t信息。\n调用函数generate_past_intervals计算past intervals的值. 调用函数build_prior构造获取pg_info_t信息的OSD列表\n调用get_infos给参与的OSD发送获取请求\n/*--------GetInfo---------*/ PG::RecoveryState::GetInfo::GetInfo(my_context ctx) : my_base(ctx), NamedState(context\u0026lt; RecoveryMachine \u0026gt;().pg-\u0026gt;cct, \u0026#34;Started/Primary/Peering/GetInfo\u0026#34;) { context\u0026lt; RecoveryMachine \u0026gt;().log_enter(state_name); PG *pg = context\u0026lt; RecoveryMachine \u0026gt;().pg; pg-\u0026gt;generate_past_intervals(); unique_ptr\u0026lt;PriorSet\u0026gt; \u0026amp;prior_set = context\u0026lt; Peering \u0026gt;().prior_set; assert(pg-\u0026gt;blocked_by.empty()); if (!prior_set.get()) pg-\u0026gt;build_prior(prior_set); pg-\u0026gt;reset_min_peer_features(); get_infos(); if (peer_info_requested.empty() \u0026amp;\u0026amp; !prior_set-\u0026gt;pg_down) { post_event(GotInfo()); } } 主OSD收到pg_info的ACK信息后封装成MNotifyRec事件发送给状态机.\n在对应react函数中对拉取的pg_info进行处理，在GetInfo状态下如果所有的副本OSD都成功将信息返回，则会投递GotInfo事件.\n状态机收到GotInfo事件后，跳转到GetLog状态，在GetLog的构造函数中\n/*------GetLog------------*/ PG::RecoveryState::GetLog::GetLog(my_context ctx) : my_base(ctx), NamedState( context\u0026lt; RecoveryMachine \u0026gt;().pg-\u0026gt;cct, \u0026#34;Started/Primary/Peering/GetLog\u0026#34;), msg(0) { context\u0026lt; RecoveryMachine \u0026gt;().log_enter(state_name); PG *pg = context\u0026lt; RecoveryMachine \u0026gt;().pg; // adjust acting? if (!pg-\u0026gt;choose_acting(auth_log_shard, false, \u0026amp;context\u0026lt; Peering \u0026gt;().history_les_bound)) { if (!pg-\u0026gt;want_acting.empty()) { post_event(NeedActingChange()); } else { post_event(IsIncomplete()); } return; } ... 调用choose_acting函数选出具有权威日志的OSD并计算wan_acting列表\n如果自己就是权威日志，则不需要拉取，直接投递GotLog事件进入下一状态\n如果自己不是权威日志，则需要去具有权威日志的OSD上去拉取，并与本地日志合并.通过发送pg_query_t::LOG事件到具有权威日志的OSD进行拉取,当收到权威日志后，封装成MLogRec类型事件\nboost::statechart::result PG::RecoveryState::GetLog::react(const MLogRec\u0026amp; logevt) { assert(!msg); if (logevt.from != auth_log_shard) { dout(10) \u0026lt;\u0026lt; \u0026#34;GetLog: discarding log from \u0026#34; \u0026lt;\u0026lt; \u0026#34;non-auth_log_shard osd.\u0026#34; \u0026lt;\u0026lt; logevt.from \u0026lt;\u0026lt; dendl; return discard_event(); } dout(10) \u0026lt;\u0026lt; \u0026#34;GetLog: received master log from osd\u0026#34; \u0026lt;\u0026lt; logevt.from \u0026lt;\u0026lt; dendl; msg = logevt.msg; post_event(GotLog()); return discard_event(); } 投递GotLog事件后，转移到GetMissing状态,进入GetMissing构造函数\n/*------GetMissing--------*/ PG::RecoveryState::GetMissing::GetMissing(my_context ctx) : my_base(ctx), NamedState(context\u0026lt; RecoveryMachine \u0026gt;().pg-\u0026gt;cct, \u0026#34;Started/Primary/Peering/GetMissing\u0026#34;) { context\u0026lt; RecoveryMachine \u0026gt;().log_enter(state_name); PG *pg = context\u0026lt; RecoveryMachine \u0026gt;().pg; assert(!pg-\u0026gt;actingbackfill.empty()); for (set\u0026lt;pg_shard_t\u0026gt;::iterator i = pg-\u0026gt;actingbackfill.begin(); i != pg-\u0026gt;actingbackfill.end(); ++i) { if (*i == pg-\u0026gt;get_primary()) continue; const pg_info_t\u0026amp; pi = pg-\u0026gt;peer_info[*i]; if (pi.is_empty()) continue; // no pg data, nothing divergent if (pi.last_update \u0026lt; pg-\u0026gt;pg_log.get_tail()) { dout(10) \u0026lt;\u0026lt; \u0026#34; osd.\u0026#34; \u0026lt;\u0026lt; *i \u0026lt;\u0026lt; \u0026#34; is not contiguous, will restart backfill\u0026#34; \u0026lt;\u0026lt; dendl; pg-\u0026gt;peer_missing[*i]; continue; } if (pi.last_backfill == hobject_t()) { dout(10) \u0026lt;\u0026lt; \u0026#34; osd.\u0026#34; \u0026lt;\u0026lt; *i \u0026lt;\u0026lt; \u0026#34; will fully backfill; can infer empty missing set\u0026#34; \u0026lt;\u0026lt; dendl; pg-\u0026gt;peer_missing[*i]; continue; } ... GetMissing处理过程中首先拉取各个从OSD的有效日志，然后用主OSD的权威日止与各个从OSD的日志进行对比，从而计算出各个从OSD上不一致的对象并保存在对应的pg_missing_t结构体中，作为后续数据修复依据.\n如果所有获取日志的请求都返回并处理完成，则调用Activate(pg-\u0026gt;get_osdmap()-\u0026gt;get_epoch()) 进入Active状态\n// all good! post_event(Activate(pg-\u0026gt;get_osdmap()-\u0026gt;get_epoch())); 到本阶段则可以说Peering主要工作已经完成,不过在接受客户端读写之前还需要执行active操作激活各个副本，该操作主要目的为固化本地peering成果，以保证其不致因为系统掉电而前功尽弃，同时还需要初始化后续在后台执行Recovery或者Backfill所依赖的关键元数据信息.\npg-\u0026gt;activate(*context\u0026lt; RecoveryMachine \u0026gt;().get_cur_transaction(), pg-\u0026gt;get_osdmap()-\u0026gt;get_epoch(), *context\u0026lt; RecoveryMachine \u0026gt;().get_on_safe_context_list(), *context\u0026lt; RecoveryMachine \u0026gt;().get_query_map(), context\u0026lt; RecoveryMachine \u0026gt;().get_info_map(), context\u0026lt; RecoveryMachine \u0026gt;().get_recovery_ctx()); 如果所有副本都被激活则投递AllReplicasActivated事件，在Active状态下处理该事件,处理过程中调用pg-\u0026gt;on_activate()函数\n在该函数中查看是否需要Recovery需要则触发DoRecovery事件；查看是否需要Backfill操作，需要则触发RequestBackfill操作.\nvoid ReplicatedPG::on_activate() { // all clean? if (needs_recovery()) { dout(10) \u0026lt;\u0026lt; \u0026#34;activate not all replicas are up-to-date, queueing recovery\u0026#34; \u0026lt;\u0026lt; dendl; queue_peering_event( CephPeeringEvtRef( std::make_shared\u0026lt;CephPeeringEvt\u0026gt;( get_osdmap()-\u0026gt;get_epoch(), get_osdmap()-\u0026gt;get_epoch(), DoRecovery()))); } else if (needs_backfill()) { dout(10) \u0026lt;\u0026lt; \u0026#34;activate queueing backfill\u0026#34; \u0026lt;\u0026lt; dendl; queue_peering_event( CephPeeringEvtRef( std::make_shared\u0026lt;CephPeeringEvt\u0026gt;( get_osdmap()-\u0026gt;get_epoch(), get_osdmap()-\u0026gt;get_epoch(), RequestBackfill()))); } else { dout(10) \u0026lt;\u0026lt; \u0026#34;activate all replicas clean, no recovery\u0026#34; \u0026lt;\u0026lt; dendl; queue_peering_event( CephPeeringEvtRef( std::make_shared\u0026lt;CephPeeringEvt\u0026gt;( get_osdmap()-\u0026gt;get_epoch(), get_osdmap()-\u0026gt;get_epoch(), AllReplicasRecovered()))); } ... Recovery 如果Primary检测自身或者任意一个Peer存在待修复的对象，将通过向状态机投递DoRecovery事件，切换到Started/Primary/Active/WaitLocalRecoveryReserved状态，开始准备执行Recovery.\nRecovery 是仅依据PG日志中的缺失记录来修复不一致的对象.\n在Activating状态接受到DoRecovery事件后，转换到WaitLocalRecoveryReserved状态.\nstruct Activating : boost::statechart::state\u0026lt; Activating, Active \u0026gt;, NamedState { typedef boost::mpl::list \u0026lt; boost::statechart::transition\u0026lt; AllReplicasRecovered, Recovered \u0026gt;, boost::statechart::transition\u0026lt; DoRecovery, WaitLocalRecoveryReserved \u0026gt;, boost::statechart::transition\u0026lt; RequestBackfill, WaitLocalBackfillReserved \u0026gt; \u0026gt; reactions; explicit Activating(my_context ctx); void exit(); }; ... 在WaitLocalRecoveryReserved构造函数中，通过request_reservation函数进行资源预留请求，资源预留是为了控制一个OSD上正在修复的PG最大数目，在主OSD和从OSD上都需要预约。当收到LocalRecoveryReserved事件后，标志本地资源预约完成.\nPG::RecoveryState::WaitLocalRecoveryReserved::WaitLocalRecoveryReserved(my_context ctx) : my_base(ctx), NamedState(context\u0026lt; RecoveryMachine \u0026gt;().pg-\u0026gt;cct, \u0026#34;Started/Primary/Active/WaitLocalRecoveryReserved\u0026#34;) { context\u0026lt; RecoveryMachine \u0026gt;().log_enter(state_name); PG *pg = context\u0026lt; RecoveryMachine \u0026gt;().pg; pg-\u0026gt;state_set(PG_STATE_RECOVERY_WAIT); pg-\u0026gt;osd-\u0026gt;local_reserver.request_reservation( pg-\u0026gt;info.pgid, new QueuePeeringEvt\u0026lt;LocalRecoveryReserved\u0026gt;( pg, pg-\u0026gt;get_osdmap()-\u0026gt;get_epoch(), LocalRecoveryReserved()), pg-\u0026gt;get_recovery_priority()); pg-\u0026gt;publish_stats_to_osd(); } 当收到LocalRecoveryReserved事件后，标志本地资源预约完成，然后转移到WaitRemoteRecoveryReserved状态\nstruct WaitLocalRecoveryReserved : boost::statechart::state\u0026lt; WaitLocalRecoveryReserved, Active \u0026gt;, NamedState { typedef boost::mpl::list \u0026lt; boost::statechart::transition\u0026lt; LocalRecoveryReserved, WaitRemoteRecoveryReserved \u0026gt; \u0026gt; reactions; explicit WaitLocalRecoveryReserved(my_context ctx); void exit(); }; 在WaitRemoteRecoveryReserved状态下，完成远程资源的预约，当接收到RemoteRecoveryReserved后表明资源都预约完成，然后投递AllRemotesReserved事件，标志着该PG在所有参与数据修复的从OSD上完成资源预约，进入Recovery状态.\nPG::RecoveryState::Recovering::Recovering(my_context ctx) : my_base(ctx), NamedState(context\u0026lt; RecoveryMachine \u0026gt;().pg-\u0026gt;cct, \u0026#34;Started/Primary/Active/Recovering\u0026#34;) { context\u0026lt; RecoveryMachine \u0026gt;().log_enter(state_name); PG *pg = context\u0026lt; RecoveryMachine \u0026gt;().pg; pg-\u0026gt;state_clear(PG_STATE_RECOVERY_WAIT); pg-\u0026gt;state_set(PG_STATE_RECOVERING); pg-\u0026gt;publish_stats_to_osd(); pg-\u0026gt;osd-\u0026gt;queue_for_recovery(pg); } 在Recoverying状态完成实际的数据修复工作\n把PG状态设置为PG_STATE_RECOVERING，并把PG添加到recovery_wq工作队列中，开始启动数据修复.\nRecovery过程由PG的主OSD来触发并控制，先修复主的，然后修复从的。\n在recovery_wq中，工作队列的线程池的处理函数调用do_recovery函数执行实际的数据修复工作.\nvoid _process(PG *pg, ThreadPool::TPHandle \u0026amp;handle) override { osd-\u0026gt;do_recovery(pg, handle); pg-\u0026gt;put(\u0026#34;RecoveryWQ\u0026#34;); } ReplicatedPG::start_recovery_ops函数完成副本类型PG的修复工作.\nbool ReplicatedPG::start_recovery_ops( int max, ThreadPool::TPHandle \u0026amp;handle, int *ops_started) { int\u0026amp; started = *ops_started; started = 0; bool work_in_progress = false; ... started = recover_replicas(max, handle); } if (!started) { // We still have missing objects that we should grab from replicas. started += recover_primary(max, handle); } ... 函数ReplicatedPG::recover_primary完成PG主OSD缺失对象的修复\n如果在Recoverying状态完成Recovery操作后，如果需要Backfill工作则接受RequestBackfill事件，进入Backfill流程\n如果没有Backfill工作，直接接受AllReplicasRecovered事件，转入Recovered状态 转入Recovered状态之后，意味着完成数据修复工作，当收到GoClean事件后，PG进入clean状态.\nBackfill 和Recovery类似，如果Primary发现还有副本需要通过Backfill才能修复，则进行Backfill。\nBackfill是PG通过重新扫描所有的对象，对比发现确实的对象，通过整体拷贝来修复。和Recovery一样需要进行资源预约.\n这部分过程就不写了\u0026hellip;\n","permalink":"https://zhxin.xyz/post/2021/05/pg-peering%E8%BF%87%E7%A8%8B%E7%8A%B6%E6%80%81%E5%8F%98%E5%8C%96%E4%BB%A3%E7%A0%81%E8%B5%B0%E8%AF%BB/","summary":"最近看了PG状态转换的过程,代码细节没有仔细研究，先粗略过了一遍代码，特此记录. PG PG是存储池的基本单元，是一些对象的集合，多副本和纠删的数据备份策略依托PG实现. PG有多种状态，状态之间的变化通过状态机实现. 有两个场景会触发peering流程： 在pg创建时 在OSD启动、停止导致OSDMap变化进而导致pg的acting set发生变化时 状态机 状态机在创建PG进行初始化. class RecoveryMachine : public boost::statechart::state_machine\u0026lt; RecoveryMachine, Initial \u0026gt; { RecoveryState *state; public: PG *pg;","title":"PG Peering过程状态变化代码走读"},{"content":"配置 git config --list --show-origin 查看所有配置信息 git config 命令带入\u0026ndash;system参数会将配置写入/etc/gitconfig文件，对整个系统生效；\u0026ndash;global选项会写入~/.gitconfig文件对当前用户所有仓库生效\n#安装完成GIT之后配置相关用户名邮箱 git config --global user.name \u0026#34;me\u0026#34; git config --global user.email me@outlook.com git config --global core.editor vim git config --global log.date iso git config --global merge.conflictstyle diff3 git config --global merge.tool nvimdiff3 配置github ssh 访问\nls -al ~/.ssh [[查看是否生成SSH]] key ssh-keygen -t rsa -b 4096 -C \u0026#34;me@outlook.com\u0026#34; [[生成key]] eval \u0026#34;$(ssh-agent -s)\u0026#34; [[保证ssh可用]] ssh-add ~/.ssh/id_rsa [[添加ssh]] key到客户端 将ssh key添加到github账户 clip \u0026lt; ~/.ssh/id_rsa.pub ssh -T git@github.com [[测试是否连接到github]] 操作 初始化 git init命令创建一个本地的仓库 git clone \u0026lt;git repo url\u0026gt;/\u0026lt;reponame\u0026gt; \u0026lt;path\u0026gt; clone一个已经存在的仓库 添加追踪文件 git add \u0026lt;file\u0026gt; 添加文件到仓库暂存区 提交: 尝试每个提交成为一个逻辑上独立的变更集，并且每个提交附带一个 有用的信息 git diff --check 检查是否有空白错误 git commit 加-a参数会跳过暂存，将所有已追踪文件一起提交 删除文件 rm file #本地删除文件，修改未放入暂存区 git rm file #修改待提交，提交完成之后文件不再跟踪 git rm -f file #删除已经修改或者已经暂存的文件 git rm --cached file #将文件从仓库中删除但是保留在本地 文件重命名 git mv old new 贮藏 git stash #贮藏当前未提交内容 git stash list #查看已经贮藏的列表 git stash apply #应用最新贮藏 git stash apply \u0026lt;stashid\u0026gt; #指定应用的贮藏 git stash pop #应用贮藏并从栈上丢弃 清理工作目录 git clean -f -d [-n] git stash --all 查询 仓库状态 git status查看当前仓库状态； git diff查看详细的未暂存文件与暂存区域的差异； git diff --staged/cached 查看对比已暂存文件与最后一次提交的文件差异; git diff master...contrib 查看当前contrib分支与master分支的共同祖先起，该分支中的工作。 提交记录 git log 按照时间顺序显示提交记录; git log -p 附带提交记录变化； git log --stat 显示缩略统计信息; git log --pretty=oneline\\full\\fuller\\short 自定义输出信息程度; 可以自定义log输出格式 git log --pretty=format:\u0026#34;%h - %an, %ar : %s\u0026#34; git log --pretty=format:\u0026#34;%h %s\u0026#34; --graph 选项 说明 %H 提交的完整哈希值 %h 提交的简写哈希值 %T 树的完整哈希值 %t 树的简写哈希值 %P 父提交的完整哈希值 %p 父提交的简写哈希值 %an 作者名字 %ae 作者的电子邮件地址 %ad 作者修订日期（可以用 \u0026ndash;date=选项 来定制格式） %ar 作者修订日期，按多久以前的方式显示 %cn 提交者的名字 %ce 提交者的电子邮件地址 %cd 提交日期 %cr 提交日期（距今多长时间） %s 提交说明 git log 常用选项\n选项 说明 -p 按补丁格式显示每个提交引入的差异。 \u0026ndash;stat 显示每次提交的文件修改统计信息。 \u0026ndash;shortstat 只显示 \u0026ndash;stat 中最后的行数修改添加移除统计。 \u0026ndash;name-only 仅在提交信息后显示已修改的文件清单。 \u0026ndash;name-status 显示新增、修改、删除的文件清单。 \u0026ndash;abbrev-commit 仅显示 SHA-1 校验和所有 40 个字符中的前几个字符。 \u0026ndash;relative-date 使用较短的相对时间而不是完整格式显示日期（比如“2 weeks ago”）。 \u0026ndash;graph 在日志旁以 ASCII 图形显示分支与合并历史。 \u0026ndash;pretty 使用其他格式显示历史提交信息。可用的选项包括 oneline、short、full、fuller 和format（用来定义自己的格式）。 \u0026ndash;oneline \u0026ndash;pretty=oneline \u0026ndash;abbrev-commit 合用的简写。 限制输出 git log -n git log --since=2.weeks --after --until --before git log --author --commiter --grep --all-match git log -S function_name git log --no-merges 简短输出 git log --abbrev-commit --pretty=oneline 分支差异查询 git log experiment..master # 在master分支而不在experiment分支中的提交 git log origin/master..HEAD # 在远程分支而不在当前分支的提交 git log refA refB --not refC # 查询所有被refA或者refB包含，但是不被refC包含的提交 git log --left-right experiment...master # 不是两个分支同时包含的提交查询 查看包含某次提交的tag git tag --contains [commitid] 搜索 使用git grep从提交历史、工作目录、索引中搜索字符串或者表达式 git grep --break --heading -n --count --show-function main git 日志搜索 git log -S ZLIB_BUF_MAX --oneline #查找ZLIB_BUF_MAX变量什么时候引入的 git log -L :git_deflate_bound:zlib.c #查看某个函数的每一次变更 git blame \u0026lt;file\u0026gt; #查看文件每一行的最后一次提交记录 回退 未提交到暂存区的回退 git checkout -- \u0026lt;file\u0026gt; git commit --amend 将暂存区文件添加到上次提交记录中，或者只修改提交信息； git reset HEAD \u0026lt;file\u0026gt; 取消文件暂存，从待提交中剔除； 修改历史提交信息或者合并历史提交 git rebase -i HEAD~n [[p]], pick = use commit [[r]], reword = use commit, but edit the commit message [[e]], edit = use commit, but stop for amending [[s]], squash = use commit, but meld into previous commit [[f]], fixup = like \u0026#34;squash\u0026#34;, but discard this commit log message [[x]], exec = run command (the rest of the line) using shell [[d]], drop = remove commit 重置 git reset --soft HEAD~ # 撤销上一次提交记录，只移动head指针，index指针不变，既上一次提交变为暂存状态 git reset [--mixed] HEAD~ # 撤销上一次提交，也会取消暂存所有东西 git reset --hard HEAD~ # 完全撤销上一次提交，上一次提交的内容被销毁 # 亦可以指定文件路径 远程仓库 查看远程仓库： git remote -v 添加远程仓库: git remote add \u0026lt;shortname\u0026gt; url 拉取远程仓库:git fetch \u0026lt;shortname\u0026gt; 拉取后会拥有那个远程仓库的所有分支的引用； 推送远程仓库: git push \u0026lt;remote\u0026gt; \u0026lt;branch\u0026gt; 查看远程仓库信息：git remote show \u0026lt;remote\u0026gt; 远程仓库重命名：git remote rename \u0026lt;old\u0026gt; \u0026lt;new\u0026gt; 删除远程仓库：git remote remove \u0026lt;name\u0026gt; 标签 列举标签：git tag -l \u0026quot;v1.8*\u0026quot; 轻量标签：git tag v1.0 [commit] 附注标签：git tag -a v1.1 -m \u0026quot;v1.1\u0026quot; [commit] 推送标签：git push origin [\u0026lt;tagname\u0026gt; [--tags--] 删除标签并推送：git tag -d \u0026lt;tagname\u0026gt;; git push origin --delete \u0026lt;tagname\u0026gt; 分支 git checkout -b \u0026lt;new_branch\u0026gt;创建分支并切换 git merget \u0026lt;hostfix\u0026gt; 合并分支，如果冲突可尝试使用git mergetool解决冲突 git branch -d hotfix 删除分支 git branch -v 查看分支 git branch --merged or --no-merged 查看merge与否的分支 git branch --no-merged master 尚未合并到master的分支 git push \u0026lt;remote\u0026gt; \u0026lt;branch\u0026gt; 将分支推送到远程仓库 git checkou --track origin/serverfix 设置当前分支追踪的远程分支 git checkout -b br origin/serverfix 检出远程分支并追踪, git checkout serverfix 如果本地没有这个分支而且远程有则会自动设置追踪 git branch -u/--set-upstream-to origin/serverfix 修改本地分支追踪上游分支 git branch -vv 显示分支的详细信息 git push origin --delete serverfix 删除远程分支 变基: 如果提交存在于你的仓库之外，而别人可能基于这些提交进行开发，那么不要执行变基, 总的原则是，只对尚未推送或分享给别人的本地修改执行变基操作清理历史， 从不对已推送至别处的提交执行变基操作，这样，你才能享受到两种方式带来的便利。 # 将experiment分支的代码以变基的方式合入master git checkout experiment git rebase master git checkout master git merge experiment # or git rebase master experiment # 变基一个与另一个分支有交集的分支，只合入该分支中的有差异部分：取出client分支,找出其与server分支分歧之后的补丁，然后把这些补丁在master分支上重放 git rebase --onto master server client 忽略文件 编辑.gitignore文件,格式规范如下: • 所有空行或者以 # 开头的行都会被 Git 忽略。 • 可以使用标准的 glob 模式匹配，它会递归地应用在整个工作区中。 • 匹配模式可以以（/）开头防止递归。 • 匹配模式可以以（/）结尾指定目录。 • 要忽略指定模式以外的文件或目录，可以在模式前加上叹号（!）取反。\nglob 模式是指 shell 所使用的简化了的正则表达式。 星号（*）匹配零个或多个任意字符；[abc] 匹配 任何一个列在方括号中的字符 （这个例子要么匹配一个 a，要么匹配一个 b，要么匹配一个 c）； 问号（?）只 匹配一个任意字符；如果在方括号中使用短划线分隔两个字符， 表示所有在这两个字符范围内的都可以匹配 （比如 [0-9] 表示匹配所有 0 到 9 的数字）。 使用两个星号（**）表示匹配任意中间目录，比如 a/**/z 可以 匹配 a/z 、 a/b/z 或 a/b/c/z 等 文件参考 gitignore\n子模块 为已经存在的项目添加子模块 git submodule add \u0026lt;url\u0026gt; \u0026lt;path\u0026gt; 克隆包含子模块的项目 git submodule init git submodule update #或者将两步合为一步 git submodule update --init git submodule update --init --recursive #递归抓取任何嵌套的子模块 #或者在clone时进行更新 git clone --recurse-submodules \u0026lt;url\u0026gt; 子模块更新 # cd进子模块目录 git fetch git merge #或者不在子目录中运行 git submodule update --remote 在子模块上工作 git submodule update --remote --merge git push --recurse-submodules=check #push前检查子模块是否已经提交 一些流程 提交代码流程 #创建dev分支进行开发 git checkout -b dev #添加文件到提交列表 git add modified_file git commit -m \u0026#34;msg\u0026#34; git checkout 本地分支名[待提交分支] git pull git merge dev git push origin 本地分支名:refs/for/远程分支名 #提交gerrit等待代码review git push origin 分支名:refs/heads/分支名 #直接提交到远程分支 #### 或者 git fetch upstream git merge upstream/master vim somefile git add somefile git commit git push origin \u0026lt;branch\u0026gt; 新建分支 #本地开好分支,推送到远程: git checkout -b feature-branch #创建并切换到分支feature-branch #推送本地的feature-branch(冒号前面的)分支到远程origin的feature-branch(冒号后面的)分支(没有会自动创建) git push origin feature-branch:feature-branch cherry-pick使用 git cherry-pick [\u0026lt;options\u0026gt;] \u0026lt;commit-ish\u0026gt;... 常用options: --quit 退出当前的chery-pick序列 --continue 继续当前的chery-pick序列 --abort 取消当前的chery-pick序列，恢复当前分支 -n, --no-commit 不自动提交 -e, --edit 编辑提交信息 ","permalink":"https://zhxin.xyz/post/2021/03/git-%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/","summary":"配置 git config --list --show-origin 查看所有配置信息 git config 命令带入\u0026ndash;system参数会将配置写入/etc/gitconfig文件，对整个系统生效；\u0026ndash;global选项会写入~/.gitconfig文件对当前用户所有仓库生效 #安装完成GIT之后配置相关用户名邮箱 git config --global user.name \u0026#34;me\u0026#34; git config --global user.email me@outlook.com git config --global core.editor vim git config --global log.date iso git config --global merge.conflictstyle diff3 git config --global merge.tool nvimdiff3 配置github ssh 访问 ls -al ~/.ssh [[查看是否生成SSH]] key ssh-keygen -t rsa -b 4096 -C \u0026#34;me@outlook.com\u0026#34; [[生成key","title":"Git 基本操作"},{"content":"转载自sysnote,如有侵权请联系删除\nceph后端支持多种存储引擎，以插件式的方式来进行管理使用，目前支持filestore，kvstore，memstore以及最新的bluestore，目前默认使用的filestore，但是因为filestore在写数据前需要先写journal，会有一倍的写放大，并且filestore一开始只是对于机械盘进行设计的，没有专门针对ssd做优化考虑，因此诞生的bluestore初衷就是为了减少写放大，并针对ssd做优化，而且直接管理裸盘，从理论上进一步减少文件系统如ext4/xfs等部分的开销，目前bluestore还处于开发优化阶段，在jewel版本还是试用版本，并且最新的master相比jewel已经做了大的重构，预期会在后续的大版本中稳定下来成为默认的存储引擎。本文基于master分支对bluestore存储引擎进行分析。\nbluestore整体架构 bluestore直接管理裸设备，抛弃了ext4/xfs等本地文件系统，BlockDevice实现在用户态下使用linux aio直接对裸设备进行I/O操作。既然是直接管理裸设备就必然需要进行裸设备的空间管理，对应的就是Allocator，目前支持StupidAllocator和BitmapAllocator两种分配器。相关的元数据以kv的形式保存到kv数据库里，默认使用的是rocksdb，由于rocksdb本身是基于文件系统的，不是直接操作裸设备，但是rocksdb也比较灵活，将系统相关的处理抽象成Env，用户可用实现相应的接口，rocksdb默认的Env是PosixEnv，直接对接本地文件系统，为此，bluestore实现了一个BlueRocksEnv，继承自EnvWrapper，来为rocksdb提供底层系统的封装，为了对接BlueRocksEnv，实现了一个小的文件系统BlueFS，只实现rocksdb Env需要的接口，在系统启动mount这个文件系统的时候将所有的元数据都加载到内存中，BluesFS的数据和日志文件都通过BlockDevice保存到裸设备上，BlueFS和BlueStore可以共享裸设备，也可以分别指定不同的设备。\nbluestore元数据 在之前的存储引擎filestore里，对象的表现形式是对应到文件系统里的文件，默认4MB大小的文件，但是在bluestore里，已经没有传统的文件系统，而是自己管理裸盘，因此需要有元数据来管理对象，对应的就是Onode，Onode是常驻内存的数据结构，持久化的时候会以kv的形式存到rocksdb里。\n在onode里又分为lextent，表示逻辑的数据块，用一个map来记录，一个onode里会存在多个lextent，lextent通过blob的id对应到blob（bluestore_blob_t ），blob里通过pextent对应到实际物理盘上的区域（pextent里就是offset和length来定位物理盘的位置区域）。一个onode里的多个lextent可能在同一个blob里，而一个blob也可能对应到多个pextent。 另外还有Bnode这个元数据，它是用来表示多个object可能共享extent，目前在做了快照后写I/O触发的cow进行clone的时候会用到。\nI/O读写映射逻辑 写I/O处理 到达bluestore的I/O的offset和length都是对象内（onode）的，offset是相对于这个对象起始位置的偏移，在_do_write里首先就会根据最小分配单位min_alloc_size进行判断，从而将I/O分为对齐和非对齐的。如下图所示：\n当一个写请求按照min_alloc_size进行拆分后，就会分为对齐写，对应到do_write_big，非对齐写（即落到某一个min_alloc_size区间的写I/O（对应到do_write_small）。\ndo_write_big 对齐到min_alloc_size的写请求处理起来比较简单，有可能是多个min_alloc_size的大小，在处理时会根据实际大小新生成lextent和blob，这个lextent跨越的区域是min_alloc_size的整数倍，如果这段区间是之前写过的，会将之前的lextent记录下来便于后续的空间回收。\ndo_write_small 在处理落到某个min_alloc_size区间的写请求时，会首先根据offset去查找有没有可以复用的blob，因为最小分配单元是min_alloc_size，默认64KB，如果一个4KB的写I/O就只会用到blob的一部分，blob里剩余的还能放其他的。\n没有找到可以复用的blob，新生成blob 在处理还还需要根据offset和len是否对齐到block_size（默认是4KB）进行补零对齐的操作，之所以需要补齐是与后续的写盘操作有关，真正写盘时有两种方式，一种是Direct I/O的方式，这种要求偏移和缓冲区都对齐的，另外一种非Direct I/O，即Buffered I/O，这种可以不对齐，但是是写到cache里，然后再sync刷到磁盘上，比如只写了100字节，在内核里是需要先从设备上读出来补齐成一个完整的扇区，然后再刷的，这样反而降低了效率。因此在bluestore里直接处理好对齐，对于后面的写盘来说比较有利，这里对齐到block_size，是个可配置的参数。 进行对齐补零时就是按照如上图那样把前后对齐到block_size，然后再把对齐后的offset和len作为lextent，进而放到blob里。\n找到可以复用的blob 对于可以复用的blob，也是先按照block_size进行对齐补零的动作，然后再判断是否可以直接使用blob里空闲的空间进行区分做不同的处理。\na. 直接写在blob未使用的空间上\n这种情况下直接新生成lextent放到blob里。\nb. 覆盖写的情况\n比如下面的这种情况，写I/O会覆盖部分已经写过的数据。\n对于这种情况的处理如下图：也是需要先处理对齐补零的情况，如果覆盖的区域刚好是已经对齐到block_size，那么就不需要从磁盘读数据，但是如果覆盖的区域没有对齐到block_size，那么就需要把不对齐的那部分读出来，拼成一个对齐的buffer，然后新生成lextent，并且会对原来那个lextent进行调整，会记录需要回收的那部分区域。对于覆盖写的情况，都不是直接写盘，而是通过wal写到rocksdb。\n读I/O的处理 读I/O请求的处理时也是通过寻找相关联的lextent，可能会存在空洞的情况，即读到未写过的数据，这部分就直接补零。\nclone及extent共享 前面说到Bnode就是用来记录共享的lextent，目前是在做完快照后对原卷进行写I/O会触发cow，从而产生clone操作。clone时就是将原对象的blob从onode-\u0026gt;blob_map移到onode-\u0026gt;bnode-\u0026gt;blob_map，并且将blob id置为负的，并设置共享标记，然后将新的快照对象的onode-\u0026gt;bnode指向原对象的onode-\u0026gt;bnode，并且用原onode里的lextents里的值赋给新的onode的lextents，从而达到共享extent的目的，图示仅供参考。\n在clone完之后，继续对原对象进行写I/O操作时，当碰到共享的blob时就需要跳过，新生成blob，并且取消对原来那部分lextent的引用，在后续的空间释放时的判断依据就是否还有引用。\n小结 本文总体上介绍了bluestore的架构、相关元数据及内部I/O映射的逻辑，这还只是bluestore的冰山一角，后续会陆续对bluestore的处理流程、空间分配器、缓存管理、压缩等实现进行分析。\n","permalink":"https://zhxin.xyz/post/2021/02/%E8%BD%AC%E8%BD%BDceph%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8Ebluestore%E8%A7%A3%E6%9E%90/","summary":"转载自sysnote,如有侵权请联系删除 ceph后端支持多种存储引擎，以插件式的方式来进行管理使用，目前支持filestore，kvstore，memstore以及最新的bluestore，目前默认使用的filestore，但是因为filestore在写数据前需要先写journal，会有一倍的写放大，并且filestore一开始只是对于机械盘进行设计的，没有专门针对ssd做优化考虑，因此诞生的bl","title":"【转载】ceph存储引擎bluestore解析"},{"content":"工作中遇到的比较常用的命令,特此整理以备忘.\n查看集群状态 ceph -s #查看状态 ceph -v #查看版本 ceph df #查询集群存储容量 ceph health detail #集群详细健康信息 查询集群组件信息相关命令 rados lspools #查询池子列表 ceph osd dump | grep pool #查询所有池子信息 rados -p \u0026lt;pool\u0026gt; ls #池子下对象 rados --pgid \u0026lt;pgid\u0026gt; ls #查看pg下对象 ceph osd map \u0026lt;pool\u0026gt; object #查看对象信息 ceph-objectstore-tool --data-path \u0026lt;datapath\u0026gt; --journal-path \u0026lt;journalpath\u0026gt; \u0026lt;objname\u0026gt; dump #输出对象元数据信息 ceph-admin-disktool --getdisks #获取磁盘信息 #mon信息 ceph mon stat ceph mon dump ceph quorum_status #osd信息 ceph osd tree ceph osd dump ceph osd find \u0026lt;numeric_osd_id\u0026gt; ceph osd df tree #查看集群空间使用率 #pg信息 ceph pg stat ceph pg dump ceph pg dump_stuck unclean systemctl管理服务 systemctl reset-failed ceph-osd@* #重置失败服务 systemctl start ceph-osd.target #重启osd服务 systemctl restart ceph.target #重启ceph服务 systemctl stop ceph-osd@0 #停止单个osd服务 systemctl status ceph-osd@1 #查看服务状态 集群操作命令 ceph osd pool delete \u0026lt;pool\u0026gt; \u0026lt;pool\u0026gt; --yes-i-really-really-mean-it #删除池 rados put \u0026lt;oid\u0026gt; \u0026lt;filename\u0026gt; --pool=\u0026lt;pool\u0026gt; #在池中添加对象 eph osd pool create \u0026lt;pool\u0026gt; \u0026lt;pgnum\u0026gt; \u0026lt;pgnum\u0026gt; -r \u0026lt;host、osd\u0026gt; #创建池 crush相关操作 ceph osd crush dump ceph osd crush rule list ceph osd crush rule dump \u0026lt;crush rule name\u0026gt; #在线修改crush rule ceph osd getcrushmap -o \u0026lt;map_old\u0026gt; #导出map crushtool -d \u0026lt;map_old\u0026gt; -o \u0026lt;map_old.txt\u0026gt; #转化成可编辑格式 vi map_old.txt #修改rule replicated_ruleset step chooseleaf firstn 0 type *osd* crushtool -c \u0026lt;map_old.txt\u0026gt; -o \u0026lt;map_new\u0026gt; #还原为map ceph osd setcrushmap -i \u0026lt;map_new\u0026gt; #将map导入ceph 块设备管理命令 ceph osd pool create \u0026lt;rbd\u0026gt; \u0026lt;pgnum\u0026gt; \u0026lt;pgnum\u0026gt; ceph osd pool set \u0026lt;rbd\u0026gt; size \u0026lt;repnum\u0026gt; rbd create --image \u0026lt;my_image\u0026gt; --size \u0026lt;1T\u0026gt; --pool \u0026lt;rbd\u0026gt; rbd ls -p \u0026lt;pool_name\u0026gt; #查看指定pool中的卷 rbd trash move/mv \u0026lt;images_name\u0026gt; -p \u0026lt;pool_name\u0026gt; #将卷丢到回收站 rbd trash restore \u0026lt;ID\u0026gt; -p \u0026lt;pool_name\u0026gt; #将回收站中的卷还原 rbd trash remove/rm \u0026lt;ID\u0026gt; -p \u0026lt;pool_name\u0026gt; #清除回收站中的卷 配置命令 ceph --show-config #查询集群默认配置 ceph daemon \u0026lt;mon.5\u0026gt; config show | grep \u0026lt;mon_osd_down_out_interval\u0026gt; #查询进程配置信息 #修改运行配置信息 临时生效 ceph tell \u0026lt;daemon-type\u0026gt;.\u0026lt;daemon id or *\u0026gt; injectargs --\u0026lt;name\u0026gt; \u0026lt;value\u0026gt; ceph tell osd.0 injectargs \u0026#39;--debug-osd 0/5\u0026#39; 其他 出现由于mon服务没有起来导致的admin_socket问题，可能原因是mon对所在分区目录空间的要求不满足(默认5%）清除部分空间即可; ","permalink":"https://zhxin.xyz/post/2021/02/%E5%B8%B8%E7%94%A8ceph%E5%91%BD%E4%BB%A4/","summary":"\u003cp\u003e工作中遇到的比较常用的命令,特此整理以备忘.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e查看集群状态\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eceph -s \u003cspan class=\"c1\"\u003e#查看状态\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eceph -v \u003cspan class=\"c1\"\u003e#查看版本\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eceph df \u003cspan class=\"c1\"\u003e#查询集群存储容量\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eceph health detail \u003cspan class=\"c1\"\u003e#集群详细健康信息\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"常用ceph命令"},{"content":" 你很自由,而她却是囚徒\n在看了四集HBO拍的 我的天才女友 的剧之后,就迫不及待的抱起书来看了.之前并没有听过这本书,也没有了解过埃莱娜费兰特这个作家,纯粹只是最近在微博上看到很多人在推荐这部剧,就好奇来看.追完更新之后,要一周的时间才能看到下一集(在这方面不得不夸奖Netflix),没耐心就去kindle上下载了书,花了大概三周的时间把那不勒斯四部曲给看完.\n故事讲述的是莉娜和莱农两个女孩从童年到老年持续一生的故事,她们是朋友也是对手,有温情也不乏冷漠,她们互为影子却又迥然不同.书中以莱农的视角讲述两人的故事,莉娜是她们城区公认的最聪明的孩子,在小学大家还都在学字母的时候她就已经在没人教的情况下会识字了,这让包括莱农在内的其他学生都相形见绌.莉娜身上有东西在吸引着莱农,两人相互试探慢慢接近最终成为了朋友.莱农在老师心目中的地位被莉娜取代,虽然心怀失落与嫉妒但是因为输给的是莉娜,莱农渐渐也就没那么难过,甚至会承认自己确实没有莉娜聪明而甘心追逐第二名的位置.两人一起做了很多事,找堂阿奇勒讨娃娃;买 小妇人 一起看想着靠文字挣很多钱;一起走过城区隧道去看大海等等.两人重要的一个分水岭是在小学毕业是否继续上学的问题,莱农经过曲折最终被家里允许继续上学,而莉娜却被要求帮家里干活,莉娜在反抗过程中甚至被爸爸扔出窗外.最终莱农进行上学,上完初中上高中最后甚至读完了大学,但是莉娜却不得不在家里的鞋店帮忙,但是莉娜自身的魔力并没有因为没上学而消失,反而在城区里面不断彰显自己的魅力.一开始莉娜并没有放弃学习还在和莱农竞争,你学意大利语我也学意大利语,你学希腊语我就学希腊语甚至要比你学的早学的更好,两人还在不断的竞争,而一段时间之后莉娜致力于帮助哥哥里诺发财,莉娜设计出款式新颖的皮鞋和哥哥一起做,最终皮鞋帮助肉食店老板斯特凡诺和索拉拉兄弟发了不小的财,同时莉娜同时被斯特凡诺和索拉拉家的马尔切诺追求,莉娜讨厌索拉拉,想靠斯特凡诺拜托马尔切诺,她以为斯特凡诺是不一样的,确不料斯特凡诺为了皮鞋的生意和索拉拉家的人达成了合作,但是莉娜最终还是嫁给了斯特凡诺开始了一段失败的婚姻\u0026hellip;.\n这基本是四部曲第一部 我的天才女友 的剧情,第二部 新名字的故事 讲述的是莉娜成为了卡拉奇太太之后发生的故事,包括莉娜被斯特凡诺家暴,流产,新开一家肉食店等等,而最重要的是和尼诺萨拉托雷的婚外情,尼诺是莱农的暗恋对象,最后和尼诺一起出逃甚至怀孕生下了一个儿子,但是尼诺却最后放弃了放弃了莉娜出逃了,莱农大学毕业后出版了一本书成为了作家. 第三部 离开的 留下的 讲述的是莉娜最终离开了斯特凡诺和恩佐在了一起,带着和尼诺生的却长得越来越像斯特凡诺的孩子,两人一起学习计算机技术,最后还开了一家BASIC SIGHT公司,莱农和很有声望的艾罗塔家族的儿子彼得罗结婚了生了两个女儿,但是狗血的是莱农和尼诺又见面了两人还在一起生了个女儿.第四部 失踪的孩子 讲述的是莱农和尼诺在一起之后和彼得罗离婚了,但是尼诺却欺骗了莱农自己没有结婚还靠着身边的女人争取这社会的地位,在莉娜的帮助下莱农最终看破了尼诺,和他分开了,并搬到了莉娜和恩佐的楼上和他们一家人住在了一起,这短时间貌似是两人关系比较和谐的一段时间,但是某一天莉娜和恩佐生的女儿,蒂娜,突然消失了,莉娜因此几乎崩溃了,孩子最终都找不到,而十几年后莱农搬到了都灵,突然有一天莉娜突然把自己从时间上回车删除了,抹除了自己在世上的痕迹,而莱农则写下了这部书.\n上面的简介剧透了不少东西但忽略的东西更多, 那不勒斯四部曲 是比较庞大的著作,以那不勒斯为背景,不仅展现了两个女人持续一生的友谊,更展示了意大利半个世纪的社会动荡,政治思潮的变化,随着莱农的成长讨论了很多共产主义,宗教,民主,女权主义等等内容.这四本书我依照自己喜欢的程度进行排名是二三一四.读第四部的时候一度想摔书,被尼诺的渣、莱农的忍给气的暴跳.尼诺曾鄙视自己的父亲但是尼诺比他父亲有过之而无不及,在尼诺欺骗的众多女人中只有莉娜是识破尼诺之后比较坚决的拒绝的,并帮助莱农不让她再自欺欺人.在众多的配角中,个人感觉刻画最生动的是莱农的母亲,一个强势,暴躁,自尊心强的母亲形象.莱农母亲在最后生病的时候说自己把全部的关心与期待都放到了莱农的身上以致忽略了莱农的妹妹弟弟,莱农获得的一切成就她都觉得是自己的功劳: 你得到的一切都是我的. 莱农母亲对莱农的爱很深也很隐晦,同时对莱农的怨与切也不遑多让.她坚持让莱农读书但也抱怨莱农不能工作挣钱,她会在莱农发烧回不了家独自迈着一瘸一拐的腿去到莱农大学的城市去看她,她会当面抱怨莱农不如莉娜但是又时时刻刻维护自己的女儿是最有出息的,莱农是她在城区昂首挺胸行走的自信源泉,她喝多酒也会暴露自己低级庸俗的乐趣但是在莱农丈夫彼得罗面前她始终坚持维持端庄自尊的形象.莱农母亲是个很矛盾的角色,也正因为其矛盾所以显得真实显得可爱.莱农一度以母亲肥大的屁股丰满的胸脯瘸拐的双腿为耻,但是莱农在母亲去世之后,愿意这些特征在自己身上能够显现,作为母亲在自己身上的投影.\n这四部曲中也有类似红楼梦中草灰蛇线,伏延千里的写法. 小时候的很多事情成了以后发生的事的隐喻. 比如莉娜和莱农小时候交换娃娃并将对方的娃娃丢掉, 她们以后在分别怀了恩佐和尼诺孩子的时候开玩笑说要交换孩子抚养,莉娜的女儿甚至和莱农当初的娃娃一样都叫蒂娜,莱农在多年以后重新收到了两个娃娃,但是蒂娜却始终没有回来; 在小时候课堂竞赛时莉娜和恩佐表现出数学上的天分,而他们以后在一起学习计算机还开了家公司;小时候莉娜怂恿莱农出城去看海,走到一半莉娜想回去了而莱农却想继续前进,在她们以后的人生中,莉娜从来没有出去过那不勒斯之外的地方而莱农却在全世界游走,最后还定居都灵,不知道在莉娜将自己在世间抹除之后有没有出走那不勒斯,去走向更广阔的世界.莉娜和莱农相互羁绊,互为影子,莉娜将莱农看成继续求学的自己,让莱农替自己学习替自己去看世界,她要求莱农必须是最好的,说过 你如果不是最好的,那我是谁,我怎么办 类似这样的话 ,莉娜从来没有想要和莱农断绝关系,甚至在莱农和尼诺在一起时不断的主动去找莱农,帮莱农识别尼诺虚伪的面目. 而对莱农来说,莉娜更像是自己学习的动力,是自己的不自信,是仅仅通过谈话就能获得写作灵感与写作技巧的对象.莱农对莉娜是又爱又怕,爱莉娜的聪明有魅力,害怕对莉娜的嫉妒与不如让自己丧失自信,变成莉娜的影子进而丧失自我.每当莱农感觉自己已经远远把落后的城区把只有小学学历的莉娜远远甩在后面的时候,莉娜总有办法让莱农感觉到自己卑微与无知,在两人的竞争中莱农并没有赢.由于小说是以莱农的视角写的,所以读者能够了解莱农的心理却只能和莱农一起去揣测莉娜的心理,让莉娜更多了一层神秘与传奇.\n小说还是比较精彩的,读到根本停不下来,四星推荐.\n","permalink":"https://zhxin.xyz/post/2021/02/%E6%88%91%E7%9A%84%E5%A4%A9%E6%89%8D%E5%A5%B3%E5%8F%8B%E8%AF%BB%E5%90%8E%E6%84%9F/","summary":"你很自由,而她却是囚徒 在看了四集HBO拍的 我的天才女友 的剧之后,就迫不及待的抱起书来看了.之前并没有听过这本书,也没有了解过埃莱娜费兰特这个作家,纯粹只是最近在微博上看到很多人在推荐这部剧,就好奇来看.追完更新之后,要一周的时间才能看到下一集(在这方面不得不夸奖Netflix),没耐心就去kindle上下载了书,花了大概三周的时间把那不勒斯四部曲给看完. 故事讲述的是莉娜和莱农两个女孩从童年到老年持","title":"我的天才女友读后感"},{"content":"应该是大二或者大三的时候第一次看是枝裕和导演的电影《无人知晓》。当时好像是看了一篇文章，介绍说柳乐优弥凭借该片击败《花样年华》梁朝伟成为了戛纳历史上最年轻的影帝。文章自然有以此为噱头吸引眼球的嫌疑，不过还是获得了我的好奇。当时和大多数人一样，新近听说了一部电影总要到豆瓣电影看看评分影评什么的，惊奇的是在豆瓣上是枝裕和导演所有作品竟然大多都是八分多的样子。就这样，我有意的多找了几部是枝裕和的作品来看。\n是枝裕和的电影一般是偏文艺的，关注家庭伦理，节奏缓慢、注重情感的积累。是不是感觉似曾相识？像山田洋次，像小津安二郎。是枝裕和自己倒说过自己受成濑巳喜男影响比较多，其实在家庭伦理片方面，日本一直有着优秀的传承，向世界展示东方的家庭伦理观，那种不说出来而对方都懂的细腻情感。\n无人知晓》讲述的是一个残忍的故事，母亲离家出走不归，大儿子负责照顾三个弟弟妹妹等待母亲回来，为了不让邻居发现，他们几乎整日地待在出租屋中，最后弟弟被饿死，大儿子乘列车将弟弟埋在山上。故事很残酷，是枝裕和的镜头却很冷静客观，孩子们的一颦一笑、迷惘忧伤，都捕捉的很到位。之后还看了导演的《步履不停》、《奇迹》，也是以家庭为主题，节奏不急不缓，电影的高潮在于情感累积到某个程度的迸发。总的来说，是枝导演的电影大多看完并不会让人有轻松的感觉，反而是心里面沉甸甸的，像被堵塞了什么东西似的让人陷入比较长的情绪低落期。\n生活是这么残酷又美好，没有希望，也没有绝望，只能愿你能够安抚心中的苦楚，一步一步的走下去…\n是枝裕和最近的几部影片故事性有所增强，更容易吸引人看下去，不比之前的影片比较“沉闷”。《如父如子》讲述的是两个家庭抱错孩子的故事，探讨亲情到底是血缘还是陪伴；《海街日记》讲述的是三姐妹接纳同父异母的妹妹的故事，影片拍摄的很美，四姐妹都很出彩，是一个相当温暖的故事；《比海更深》其实故事性相对没有那么强，比较偏向之前的作品，讲述一个自称小说家体验生活的私家侦探由于赌博离婚之后依然对妻子和孩子割舍不下想要挽回的故事，影片的高潮落根于台风的夜晚良多（导演很多不同影片男主人公都叫这个名字）和母亲、良多妻子和母亲的谈心，虽然悔不当初，但是终归是回不去的。最后母亲(树木希林扮演)说的这句话不禁让人唏嘘感慨。\n活了这么多年，我还从来没有这么一个人，可以说我爱他比海更深…\n前段时间又看了是枝裕和导演的《小偷家族》，该片获得了戛纳金棕榈大奖，有很多之前影片的影子。最近树木希林女士去世了,她和是枝也是“如母如子”了，是枝也说自己重新经历了丧母之痛。\n","permalink":"https://zhxin.xyz/post/2020/04/%E5%85%B3%E4%BA%8E%E6%98%AF%E6%9E%9D%E8%A3%95%E5%92%8C/","summary":"应该是大二或者大三的时候第一次看是枝裕和导演的电影《无人知晓》。当时好像是看了一篇文章，介绍说柳乐优弥凭借该片击败《花样年华》梁朝伟成为了戛纳历史上最年轻的影帝。文章自然有以此为噱头吸引眼球的嫌疑，不过还是获得了我的好奇。当时和大多数人一样，新近听说了一部电影总要到豆瓣电影看看评分影评什么的，惊奇的是在豆瓣上是枝裕和导演所有作品竟然大多都是八分多的样子。就这样，我有意的多找了几部是枝裕和的作品来看","title":"关于是枝裕和"},{"content":"28岁、单身、无业、泡图书馆， 追剧看到这几个关键词的时候自己难免会心一笑，因为这几个标签可以完美套在当下的自己身上。 毕业后的第一份工作在坚持了几年之后还是最近提出了离职。自然没有剧中那样极具戏剧冲突的意外会让你突然决定离职来开始新的生活，现实中的职场只会让你在一眼看得到头的日子中精神被一点点摧残直到濒临崩溃。28岁是很尴尬的年龄，明明感觉正年轻，是孩提时向往的能够自由独立、天高任鸟飞的时候，但是现实却是从未有过的迷茫，比大学刚毕业的时候有过之而无不及。凪在图书馆中呆到最后也写不出愿望清单中的一项，反正不知道别人怎样，自己却是真的不知道干什么的，只是被动的选了专业，毕业后从事专业相关的工作。也不是没有喜欢的事情，不过不确定喜欢的事情是否能够养活自己，甚至父母将自己的工资和他们听说的别人家的孩子比较之后会说：工资也不高呀… 辞职的事情是没有告诉家人的，所以很怕接到家里的电话。不太有追求喜欢事情的念头，因为不自信，因为不确定是否足够喜欢，那种可以义无反顾破釜沉舟的人可能永远对这样的人感到无法理解，我是那种永远在被生活推着向前走的人。\n离职后的日子还是比较焦躁的，和凪一样，有害怕积蓄花光的焦虑。大多数同龄人早已家庭事业双丰收，即使生活的辛苦并没有饶过谁，但是他们至少有奋斗的动力与身心俱疲后的避风港，而自己却一直在泥沼中挣扎，即使不断的手动足摇，但停下后依然还是在原地。凪说自己：特别喜欢SNS 对人对事也特别有执念 唯一的兴趣就是节俭，在社会关系中，敏感的人总是那么容易格格不入，总是在为别人考虑中扭曲了自己，别人将自己的和气当做没脾气、把好心当做随便使唤的义工，所以慢慢的打交道的事情总是能免就免了，也不想为了别人的看法而改变自己，可是同样的事情再次出现的时候难免还是会破功。凪将自己翻身的机会寄托到将来把和慎二结婚的消息发布SNS的那刻，也许她把能够和八面玲珑随时随地是氛围中心的慎二在一起当做自己唯一破除壁垒改变生活的机会，但是剧情的设置是残酷的最终导致凪抛弃一切去开始新生活。\n说到这个慎二感觉他有点对凪精神虐待的意思，一开始看到慎二的标准反派表现感觉高桥一生这次在剧中应该是打酱油的吧，谁知道后来编剧给慎二强行‘洗白’：对凪所做的一切只是由于不会表达爱。编剧也写出了类似男女之间悲剧的导火索总是因为话说的不到位这种日剧金句。慎二在剧中处处打击凪的自尊心，不管有心还是无意。《冷暴力》中有这样一段描述精神虐待:\n施虐者却是以一贯的邪恶方式虐待别人，并固执地维持这种特定形式的关系…这种人为满足自身对获得倾慕和肯定的无尽需求，一定要以贬抑他人的方式来维护自尊，继而握有权力。由于他们不在乎与他人的关系，也就不会有同理心，也不会懂得尊重别人。\n总之感觉慎二这个角色写的有点问题，不是高桥一生演的不好，之前看他演的四重奏就挺好的。 大龄未婚男女青年感觉是个容易在微博知乎这样的地方引起热议的话题，甚至拿女博士这样厉害的人拿来调侃，貌似没有结婚的人生就是失败的。有人觉得结婚需要的是爱，有的觉得是门当户对，有的觉得房子车子不能少，有的觉得有情饮水饱，对此我也没有能力跳脱出来说些免于世俗亦或理想超脱的话。很长一段时间包括现在都怀疑自己是否有爱的能力，就是不清楚到什么程度才能够说是爱，目前只知道什么是喜欢，歇斯底里是永远做不到的，对激烈而又极端的恋侣们始终无法理解。到了奔三的年纪即使自己觉得结婚不着急，父母催婚也能搞得你崩溃，相亲这种活动对敏感而社恐的人来说简直致命，所以只能骗父母说已经有对象在谈来换得片刻的安静，继而在生活的泥沼中继续挣扎。对于婚姻要么是过于理想要么是过于消极。也许最终还是得和能够温暖慰藉到自己的人在一起才舒服吧，也许这又是理想化了。在现实浮躁的社会中期望通过这样的断舍离来获得新生活的努力终归是徒劳，起码我觉得自己这段离职休假并不会改变什么，不过剧中应该是圆满结局。写了这篇杂乱无章的东西只是因为这部剧(只看了前两集)和自己目前的状态有所呼应而已，可能这部剧这么受关注也是因为触动了当前奔三路上的人们的一些敏感神经吧，就这样吧，感谢听我啰嗦，希望大家幸福。\n","permalink":"https://zhxin.xyz/post/2019/08/%E4%B8%8D%E4%BC%9A%E5%88%B0%E6%9D%A5%E7%9A%84%E6%96%B0%E7%94%9F%E6%B4%BB/","summary":"28岁、单身、无业、泡图书馆， 追剧看到这几个关键词的时候自己难免会心一笑，因为这几个标签可以完美套在当下的自己身上。 毕业后的第一份工作在坚持了几年之后还是最近提出了离职。自然没有剧中那样极具戏剧冲突的意外会让你突然决定离职来开始新的生活，现实中的职场只会让你在一眼看得到头的日子中精神被一点点摧残直到濒临崩溃。28岁是很尴尬的年龄，明明感觉正年轻，是孩提时向往的能够自由独立、天高任鸟飞的时候，但是现","title":"不会到来的新生活"}]